# Splink Duplikaterkennung mit persistenter DuckDB

## ğŸš€ Neue Features: Persistente DuckDB-Integration

### **Hauptverbesserungen:**
- **Persistente DuckDB-Datei**: Alle Daten werden in `output/splink_data.duckdb` gespeichert
- **Performance-Optimierung**: Keine CSV-Parsing bei jedem Lauf
- **Intelligente Caching**: Automatische Erkennung ob Daten aktualisiert werden mÃ¼ssen
- **Datenbankstatistiken**: Umfassende Einblicke in die Datenbank
- **Flexible Verwaltung**: Exportieren, AufrÃ¤umen und Statistiken anzeigen

## ğŸ“Š Neue CLI-Optionen

### **Datenbankoperationen:**
```bash
# Datenbankstatistiken anzeigen
uv run python -m src.dublette.app --show-db-stats

# Alle Tabellen als CSV exportieren
uv run python -m src.dublette.app --export-db-to-csv

# TemporÃ¤re Tabellen aufrÃ¤umen und optimieren
uv run python -m src.dublette.app --cleanup-db
```

### **Performance-Optionen:**
```bash
# Vorhandene Ergebnisse verwenden (wenn verfÃ¼gbar)
uv run python -m src.dublette.app --use-existing-results

# Alle Tabellen forciert neu laden
uv run python -m src.dublette.app --generate-test-data --force-refresh
```

## ğŸ¯ Typische Workflows

### **1. Erstes Setup (wie gewohnt):**
```bash
# Erstmalige Testdaten generieren
uv run python -m src.dublette.app --generate-test-data

# Mit Enhanced Normalization
uv run python -m src.dublette.app --generate-test-data --enhanced-normalization
```

### **2. Schnelle Wiederholung (NEU):**
```bash
# Verwendet vorhandene Daten aus der Datenbank
uv run python -m src.dublette.app

# Mit vorhandenen Ergebnissen (noch schneller)
uv run python -m src.dublette.app --use-existing-results
```

### **3. Datenbankmanagement (NEU):**
```bash
# Ãœbersicht Ã¼ber die Datenbank
uv run python -m src.dublette.app --show-db-stats

# Backup als CSV-Dateien
uv run python -m src.dublette.app --export-db-to-csv

# Optimierung der Datenbank
uv run python -m src.dublette.app --cleanup-db
```

## ğŸ”§ Intelligente Funktionen

### **Automatische Datenverwaltung:**
- **Zeitstempel-PrÃ¼fung**: LÃ¤dt nur neue CSV-Dateien
- **Existenz-PrÃ¼fung**: Verwendet vorhandene Datenbanktabellen
- **Backward Compatibility**: CSV-Dateien werden weiterhin fÃ¼r KompatibilitÃ¤t erstellt

### **Datenbankoptimierung:**
- **Komprimierte Speicherung**: DuckDB speichert effizienter als CSV
- **Schnelle Abfragen**: Direkte SQL-Operationen ohne Parsing
- **Intelligente Views**: Automatische Erstellung fÃ¼r verschiedene Modi

## ğŸ“ˆ Performance-Verbesserungen

### **Erwartete Zeitersparnis:**
- **Erstes Laden**: Wie gewohnt (einmalig)
- **Wiederholte LÃ¤ufe**: 70-90% schneller
- **Mit `--use-existing-results`**: 95% schneller

### **Speichereffizienz:**
- **DuckDB vs CSV**: 50-70% weniger Speicherplatz
- **Komprimierung**: Automatische Optimierung
- **Cleanup**: Entfernt temporÃ¤re Tabellen

## ğŸ—‚ï¸ Dateistruktur

```
output/
â”œâ”€â”€ splink_data.duckdb          # ğŸ†• Persistente DuckDB-Datei
â”œâ”€â”€ predictions.csv             # KompatibilitÃ¤t (mit --save-csv-files)
â”œâ”€â”€ target_table.csv            # KompatibilitÃ¤t (mit --save-csv-files)
â”œâ”€â”€ company_a_data.csv          # Originale Testdaten
â”œâ”€â”€ company_b_data.csv          # Originale Testdaten
â”œâ”€â”€ evaluation_report.md        # Umfassender Evaluationsbericht
â””â”€â”€ *.png                       # Evaluations-Plots
```

## ğŸ“Š Datenbank-Schema

### **Haupttabellen:**
- `company_a_raw` / `company_b_raw`: Originale Testdaten
- `partnerdaten_raw`: Benutzerdefinierte Eingabedaten
- `company_data`: Normalisierte Haupttabelle fÃ¼r Single-Table-Modus
- `company_data_a` / `company_data_b`: Normalisierte Tabellen fÃ¼r Multi-Table-Modus
- `predictions`: Duplikat-Vorhersagen mit Wahrscheinlichkeiten
- `target_table`: Deduplizierte Zieltabelle
- `deduplicated_data`: Finale bereinigte Daten

### **Views:**
- `company_data_a` / `company_data_b`: Standardisierte Ansichten fÃ¼r Multi-Table-Modus

## ğŸ› ï¸ Erweiterte Verwendung

### **KompatibilitÃ¤t:**
```bash
# Alte Kommandos funktionieren weiterhin
uv run python -m src.dublette.app --input-file data.csv
uv run python -m src.dublette.app --multi-table --generate-test-data

# Neue Optionen sind additiv
uv run python -m src.dublette.app --input-file data.csv --use-existing-results
```

### **Entwicklung & Debugging:**
```bash
# VollstÃ¤ndige Neugenerierung
uv run python -m src.dublette.app --generate-test-data --force-refresh

# Nur Datenbankstatistiken
uv run python -m src.dublette.app --show-db-stats

# Alles exportieren und aufrÃ¤umen
uv run python -m src.dublette.app --export-db-to-csv --cleanup-db
```

## ğŸ‰ Vorteile der neuen Implementierung

### **FÃ¼r Entwickler:**
- **Schnellere Iteration**: Weniger Wartezeit zwischen Tests
- **Bessere Ãœbersicht**: Datenbankstatistiken zeigen alle Daten
- **Flexibler**: Verschiedene Workflows fÃ¼r verschiedene Szenarien

### **FÃ¼r Produktivumgebungen:**
- **Robuste Datenhaltung**: Persistent zwischen Sessions
- **Performance**: Optimierte Abfragen und Joins
- **Skalierbarkeit**: DuckDB skaliert besser als CSV

### **FÃ¼r Experimente:**
- **Caching**: Ergebnisse bleiben verfÃ¼gbar
- **Vergleiche**: Verschiedene Schwellwerte ohne Neuberechnung
- **Backup**: Einfacher Export fÃ¼r Archivierung

## ğŸ”„ Migration von bestehenden Projekten

### **Automatisch:**
- Beim ersten Lauf werden CSV-Dateien automatisch in die Datenbank importiert
- Bestehende Workflows funktionieren unverÃ¤ndert
- CSV-Dateien werden weiterhin fÃ¼r KompatibilitÃ¤t erstellt

### **Manuell (optional):**
```bash
# Bestehende Daten in Datenbank importieren
uv run python -m src.dublette.app --force-refresh

# DatenbankÃ¼bersicht
uv run python -m src.dublette.app --show-db-stats
```

**Fazit**: Die persistente DuckDB-Integration macht das System erheblich effizienter, ohne die Einfachheit und KompatibilitÃ¤t zu beeintrÃ¤chtigen! ğŸš€
