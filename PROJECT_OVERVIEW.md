# Splink Dublette - ProjektÃ¼bersicht

## ğŸ¯ Projektbeschreibung

**Splink Dublette** ist ein production-ready Proof of Concept fÃ¼r Record Linkage und Duplikaterkennung mit deutschen Datenstrukturen. Das System kombiniert Splink v4, persistente DuckDB-Speicherung, umfassende Datennormalisierung und Referenz-System-Benchmarking zu einer produktionsreifen LÃ¶sung.

## ğŸ—ï¸ Architektur

### Kernmodule
- **`src/dublette/app.py`**: Haupteinstiegspunkt mit vereinfachtem CLI
- **`src/dublette/data/normalization.py`**: Deutsche Datennormalisierung (Standard + Enhanced)
- **`src/dublette/database/connection.py`**: DuckDB-Integration mit persistenter Speicherung
- **`src/dublette/detection/splink_config.py`**: Splink-Konfiguration fÃ¼r deutsche Daten
- **`src/dublette/evaluation/metrics.py`**: Umfassende Evaluation mit Visualisierungen

### Datenarchitektur
```
Persistente DuckDB: output/splink_data.duckdb
â”œâ”€â”€ company_data_raw         # Original CSV-Daten
â”œâ”€â”€ company_data             # Normalisierte CSV-Daten (Single-Table)
â”œâ”€â”€ predictions              # Splink-Ergebnisse
â”œâ”€â”€ target_table             # Deduplizierte DatensÃ¤tze
â”œâ”€â”€ reference_duplicates     # Referenz-System-Duplikate (SATZNR_1, SATZNR_2)
â””â”€â”€ predictions_with_reference # Enhanced Predictions mit Referenz-Flags
```

## ğŸ”§ CLI Interface

### Vereinfachtes 4-Parameter CLI
```bash
# VollstÃ¤ndiger Workflow
uv run python -m dublette.app --load-data data.csv --load-reference ref.csv --predict --evaluate

# Schrittweise AusfÃ¼hrung
uv run python -m dublette.app --load-data data.csv
uv run python -m dublette.app --load-reference ref.csv
uv run python -m dublette.app --predict
uv run python -m dublette.app --evaluate

# Nur Datenverarbeitung (ohne Vorhersage)
uv run python -m dublette.app --load-data data.csv --load-reference ref.csv
```

### Parameter
- `--load-data FILE`: CSV-Datei einlesen â†’ `company_data_raw` â†’ `company_data` (normalisiert)
- `--load-reference FILE`: CSV mit Referenz-Duplikaten â†’ `reference_duplicates` (SATZNR_1, SATZNR_2)
- `--predict`: Single-Table-Deduplikation â†’ `predictions` + `target_table` + `predictions_with_reference`
- `--evaluate`: Evaluation-Report und Statistiken generieren

## ğŸ‡©ğŸ‡ª Deutsche Datenstrukturen

### Standardisierte Spaltennamen
```
SATZNR          # Eindeutige ID
NAME            # Nachname/Firmenname  
VORNAME         # Vorname
GEBURTSDATUM    # Datum (YYYY-MM-DD)
GESCHLECHT      # M/W/D
LAND            # LÃ¤ndercode (DE/AT/CH)
POSTLEITZAHL    # Deutsche PLZ
ORT             # Stadt
ADRESSZEILE     # VollstÃ¤ndige Adresse
```

### Normalisierung
- **Standard-Mode**: Umlaute, StraÃŸenabkÃ¼rzungen, phonetische Regeln
- **Enhanced-Mode**: Soundex, Fuzzy-Matching, NLP-Adressen (mit `jellyfish`)

## ğŸš€ Hauptfeatures

### 1. Persistente DuckDB-Architektur
- Alle Daten in `output/splink_data.duckdb`
- 70-90% Performance-Verbesserung bei WiederholungslÃ¤ufen
- Intelligente Zeitstempel-basierte Aktualisierung
- Backup-freundlicher CSV-Export

### 2. Splink v4 Integration
- **Single-Table-Deduplication**: Duplikaterkennung innerhalb einer Datenquelle
- Erweiterte Blocking Rules fÃ¼r deutsche Daten
- Kombinierte Strategien (NAME+VORNAME, PLZ+ORT, etc.)
- Threshold-basierte Match-Klassifikation (Standard: 0.8)

### 3. Referenz-System-Benchmarking
- Import von Referenz-Duplikaten (z.B. `output/bewertung.csv`)
- Precision/Recall/F1-Score Berechnung
- Confusion Matrix Analyse
- Erweiterte Predictions-Tabelle mit Referenz-Flags

### 4. Umfassende Evaluation
- 6-Plot-Analyse mit deutschen ErklÃ¤rungen
- Automatischer Markdown-Bericht
- Threshold-SensitivitÃ¤ts-Analyse
- QualitÃ¤tsindikatoren und VerbesserungsvorschlÃ¤ge

## ğŸ“Š Ausgabedateien

```
output/
â”œâ”€â”€ splink_data.duckdb                       # Persistente Hauptdatenbank
â”œâ”€â”€ evaluation_report.md                     # Umfassender Evaluationsbericht
â”œâ”€â”€ comprehensive_evaluation_analysis.png
â”œâ”€â”€ detailed_threshold_analysis.png
â”œâ”€â”€ match_quality_heatmap.png
â”œâ”€â”€ match_probability_distribution.png
â”œâ”€â”€ predictions.csv                          # Splink-Vorhersagen
â””â”€â”€ target_table.csv                        # Deduplizierte Zieltabelle
```

## ğŸ”„ Workflows

### 1. CSV Input Processing
```
CSV file â†’ company_data_raw â†’ normalize â†’ company_data
```

### 2. Reference Data Loading
```
Reference CSV â†’ reference_duplicates (SATZNR_1, SATZNR_2)
```

### 3. Single-Table Deduplication
```
company_data â†’ predictions â†’ target_table
```

### 4. Reference Benchmarking
```
predictions + reference_duplicates â†’ predictions_with_reference
```

## ğŸ› ï¸ Technische Details

### Dependencies
- **Core**: `splink`, `duckdb`, `pandas`, `click`
- **Visualization**: `matplotlib`, `seaborn`
- **Enhanced**: `jellyfish` (optional fÃ¼r phonetische Algorithmen)

### Performance
- **Erstes Laden**: Setup-Zeit fÃ¼r Datenbank
- **Wiederholte LÃ¤ufe**: 70-90% schneller durch Caching
- **Enhanced Normalization**: 20-30% langsamer, deutlich bessere QualitÃ¤t

### Konfiguration
- Threshold: 0.8 (standard)
- Blocking Rules: NAME, PLZ, ORT, Kombinationen
- Similarity: Levenshtein, ExactMatch fÃ¼r deutsche Felder
- Single-Table-Modus: Nur Deduplikation (keine Multi-Table-Links)

## ğŸ¯ AnwendungsfÃ¤lle

1. **Kundendaten-Deduplikation**: CSV-Import mit Single-Table-Deduplikation
2. **QualitÃ¤tsbenchmarking**: Vergleich mit bestehenden Duplikaterkennungssystemen
3. **DatenqualitÃ¤ts-Assessment**: Umfassende Evaluation und Reporting
4. **Produktionssystem-Validation**: Referenz-basierte Precision/Recall-Analyse

## âš ï¸ Aktueller Status

### Standard-Konfiguration
- Enhanced Normalization ist standardmÃ¤ÃŸig aktiviert
- Single-Table-Deduplikation als Kern-Feature
- Threshold 0.8 fÃ¼r Match-Klassifikation
- Referenz-Statistiken in `--evaluate` integriert

### Entfernte Features (Vereinfachung)
- âŒ Multi-Table-Linking (war: `company_data_a/b`)
- âŒ Testdatengenerierung (war: `--generate-test-data`)
- âŒ Separater `--reference-stats` Modus
- âŒ Prediction-Modi (`input`/`generated`)

### Visualisierungen
- Evaluation-Plots sind implementiert in `metrics.py`
- KÃ¶nnen bei Bedarf in `--evaluate` aktiviert werden
- Report-Generierung ist vollstÃ¤ndig funktional

### CLI-Aufrufe
```bash
# VollstÃ¤ndiger Workflow
uv run python -m dublette.app --load-data data.csv --load-reference ref.csv --predict --evaluate

# Schrittweise
uv run python -m dublette.app --load-data data.csv
uv run python -m dublette.app --load-reference ref.csv  
uv run python -m dublette.app --predict
uv run python -m dublette.app --evaluate
```

## ğŸ“‹ NÃ¤chste Schritte fÃ¼r neue Chats

1. **Aktueller Status prÃ¼fen**: `show_database_statistics()` â†’ TabellengrÃ¶ÃŸe und -status
2. **Testlauf**: `uv run python -m dublette.app --load-data data.csv --predict --evaluate`
3. **Datenbank-Status**: PrÃ¼fung der Tabellen in `output/splink_data.duckdb`
4. **Referenz-Vergleich**: `--load-reference` fÃ¼r Benchmarking verwenden

## ğŸ” Debugging & Troubleshooting

### HÃ¤ufige Probleme
- **Module nicht gefunden**: Sicherstellen dass `PYTHONPATH` korrekt gesetzt ist
- **DuckDB-Locks**: Alte Verbindungen mit `cleanup_database()` schlieÃŸen
- **Speicher-Issues**: Enhanced Normalization bei groÃŸen Datasets deaktivieren

### Logs & Monitoring
- Alle wichtigen Schritte werden mit Emojis und Fortschrittsanzeigen geloggt
- Database Statistics zeigen TabellengrÃ¶ÃŸe und -status
- Evaluation Metrics geben detaillierte QualitÃ¤tsinformationen

---
*Stand: Production-ready POC mit persistenter DuckDB-Architektur und deutscher Lokalisierung* ğŸ‡©ğŸ‡ª  
*Fokus: Single-Table-Deduplikation mit Referenz-System-Benchmarking*

**Erstellt am:** 14. Juli 2025  
**Letzte Aktualisierung:** 14. Juli 2025 (Vereinfachung auf 4 Kernfunktionen)  
**FÃ¼r neue Chats:** Diese Datei als Kontext-Basis verwenden
