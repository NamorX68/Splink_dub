# Splink Duplikaterkennung - Production-Ready POC

Ein **modularer Proof of Concept** fÃ¼r Record Linkage und Duplikaterkennung mit deutschen Datenstrukturen. Das System kombiniert Splink v4, persistente DuckDB-Speicherung, umfassende Datennormalisierung und **Referenz-System-Benchmarking** zu einer produktionsreifen LÃ¶sung.

## ğŸš€ Quick Start

```bash
# Installation
uv sync

# VollstÃ¤ndiger Workflow
uv run python -m dublette.app --load-data data.csv --load-reference ref.csv --predict --evaluate

# Schrittweise AusfÃ¼hrung
uv run python -m dublette.app --load-data data.csv
uv run python -m dublette.app --load-reference ref.csv  
uv run python -m dublette.app --predict
uv run python -m dublette.app --evaluate

# Nur Datenverarbeitung (ohne Vorhersage)
uv run python -m dublette.app --load-data data.csv --load-reference ref.csv
```

## âœ¨ Hauptfeatures

### ğŸ—ï¸ **Persistente DuckDB-Architektur**
- **Dauerhafte Speicherung**: Alle Daten in `output/splink_data.duckdb`
- **Intelligente Caching**: Zeitstempel-basierte Aktualisierung
- **Performance**: 70-90% schneller bei WiederholungslÃ¤ufen
- **Backup-freundlich**: Einfacher Export als CSV

### ğŸ‡©ï¿½ **Deutsche Datennormalisierung**
- **Standard-Mode**: Umlaute, StraÃŸenabkÃ¼rzungen, phonetische Regeln
- **Enhanced-Mode**: Soundex, Fuzzy-Matching, NLP-Adressen (mit jellyfish)
- **Backward-Compatible**: Funktioniert mit bestehenden Daten
- **Flexibel**: Ein-/ausschaltbar per CLI-Parameter

### ğŸ“Š **Umfassende Evaluation**
- **6-Plot-Analysis**: Wahrscheinlichkeitsverteilung, Threshold-SensitivitÃ¤t, QualitÃ¤tsindikatoren
- **Markdown-Bericht**: Automatisch generierter Evaluationsbericht
- **VerstÃ¤ndliche Metriken**: Deutsche ErklÃ¤rungen und Empfehlungen
- **Visualisierungen**: 4 verschiedene Plot-Sets fÃ¼r tiefe Einblicke

### âš¡ **Vereinfachte Splink-Features**
- **Single-Table-Deduplikation**: Fokus auf Duplikaterkennung innerhalb einer Datenquelle
- **Kombinierte Blocking Rules**: NAME+VORNAME, PLZ+ORT, phonetische Ã„hnlichkeit
- **Deutsche Datenstrukturen**: Optimiert fÃ¼r SATZNR, NAME, VORNAME, etc.
- **Threshold-basierte Klassifikation**: Standard-Threshold 0.8

## ğŸ”§ Vereinfachtes CLI Interface

Das CLI wurde auf **4 essenzielle Parameter** reduziert fÃ¼r maximale Klarheit:

### **Kern-Usage**

```bash
# VollstÃ¤ndiger Workflow
uv run python -m dublette.app --load-data companies.csv --load-reference duplicates.csv --predict --evaluate

# Schrittweise AusfÃ¼hrung
uv run python -m dublette.app --load-data companies.csv
uv run python -m dublette.app --load-reference duplicates.csv
uv run python -m dublette.app --predict
uv run python -m dublette.app --evaluate

# Nur Datenverarbeitung
uv run python -m dublette.app --load-data companies.csv --load-reference duplicates.csv

# Ohne Referenz-System
uv run python -m dublette.app --load-data companies.csv --predict --evaluate
```
