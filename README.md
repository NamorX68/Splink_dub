
# Splink Duplikaterkennung ‚Äì Modularer POC

Ein **modularer Proof of Concept** f√ºr Record Linkage und Duplikaterkennung mit deutschen Datenstrukturen. Das System kombiniert Splink v4, persistente DuckDB-Speicherung, umfassende Datennormalisierung und **Referenz-System-Benchmarking** zu einer produktionsreifen L√∂sung. Die CLI ist strikt modular aufgebaut und unterst√ºtzt alle Workflows einzeln oder kombiniert.


## üöÄ Quick Start

```bash
# Installation
uv sync

# Vollst√§ndiger Workflow (alle Schritte in einem Durchlauf)
uv run python -m dublette.app --load-data input/partnerdaten.csv --load-reference input/bewertung.csv --train --predict

# Schrittweise Ausf√ºhrung (empfohlen f√ºr Analyse und Debugging)
uv run python -m dublette.app --load-data input/partnerdaten.csv
uv run python -m dublette.app --load-reference input/bewertung.csv
uv run python -m dublette.app --train
uv run python -m dublette.app --predict

# Datenexploration (optional, vor Training)
uv run python -m dublette.app --explore

# Nur Datenverarbeitung (ohne Training/Vorhersage)
uv run python -m dublette.app --load-data input/partnerdaten.csv --load-reference input/bewertung.csv
```

## ‚ú® Hauptfeatures

### üèóÔ∏è **Persistente DuckDB-Architektur**
- **Dauerhafte Speicherung**: Alle Daten in `output/splink_data.duckdb`
- **Intelligente Caching**: Zeitstempel-basierte Aktualisierung
- **Performance**: 70-90% schneller bei Wiederholungsl√§ufen
- **Backup-freundlich**: Einfacher Export als CSV

### üá©ÔøΩ **Deutsche Datennormalisierung**
- **Standard-Mode**: Umlaute, Stra√üenabk√ºrzungen, phonetische Regeln
- **Enhanced-Mode**: Soundex, Fuzzy-Matching, NLP-Adressen (mit jellyfish)
- **Backward-Compatible**: Funktioniert mit bestehenden Daten
- **Flexibel**: Ein-/ausschaltbar per CLI-Parameter

### üìä **Umfassende Evaluation**
- **6-Plot-Analysis**: Wahrscheinlichkeitsverteilung, Threshold-Sensitivit√§t, Qualit√§tsindikatoren
- **Markdown-Bericht**: Automatisch generierter Evaluationsbericht
- **Verst√§ndliche Metriken**: Deutsche Erkl√§rungen und Empfehlungen
- **Visualisierungen**: 4 verschiedene Plot-Sets f√ºr tiefe Einblicke

### ‚ö° **Vereinfachte Splink-Features**
- **Single-Table-Deduplikation**: Fokus auf Duplikaterkennung innerhalb einer Datenquelle
- **Kombinierte Blocking Rules**: NAME+VORNAME, PLZ+ORT, phonetische √Ñhnlichkeit
- **Deutsche Datenstrukturen**: Optimiert f√ºr SATZNR, NAME, VORNAME, etc.
- **Threshold-basierte Klassifikation**: Standard-Threshold 0.8


## üîß CLI-Parameter und Workflows

Die CLI unterst√ºtzt folgende Workflows, die beliebig kombiniert werden k√∂nnen:

- `--load-data <FILE>`: L√§dt CSV-Daten in die Datenbank (z.B. Firmenstammdaten)
- `--load-reference <FILE>`: L√§dt Referenz-Duplikate (z.B. Bewertungsdaten)
- `--train`: Erstellt und trainiert das Splink-Modell (Blocking Rules, Vergleichslogik, Report)
- `--predict`: F√ºhrt die Dubletten-Vorhersage aus und speichert die Ergebnisse
- `--explore`: Interaktive Datenexploration (Profiling, Visualisierung)

### Beispiele

```bash
# Komplett-Workflow (empfohlen f√ºr Benchmarking)
uv run python -m dublette.app --load-data input/partnerdaten.csv --load-reference input/bewertung.csv --train --predict

# Nur Training und Report
uv run python -m dublette.app --train

# Nur Vorhersage (nach Training)
uv run python -m dublette.app --predict

# Datenexploration
uv run python -m dublette.app --explore


# Nur Daten laden
uv run python -m dublette.app --load-data input/partnerdaten.csv
uv run python -m dublette.app --load-reference input/bewertung.csv
```

---


## üìù ToDo

### Blocking Rules
- Schrittweise Erweiterung und Testen neuer Blocking Rules:
  - [x] NAME
  - [x] VORNAME
  - [ ] NAME+VORNAME
  - [ ] PLZ
  - [ ] PLZ+ORT
  - [ ] Phonetische Varianten (Soundex, Metaphone)
- [ ] Analyse der Vergleichsanzahl und Qualit√§t je Blocking Rule
- [ ] Automatisierte Bewertung und Report-Generierung f√ºr jede Blocking Rule


### Training & Modell
- [x] Optimierung der Trainingslogik (z.B. Parameterwahl, Feature-Auswahl)
- [x] Vergleich verschiedener Trainingsdaten (balanciert/unbalanciert)
- [x] Threshold-Optimierung und Sensitivit√§tsanalyse
- [x] Logging und Monitoring der Trainingsl√§ufe
- [ ] Automatisierte Tests f√ºr Trainings-Workflow


### Weitere Aufgaben
- [x] Erweiterte Evaluation/Reporting (z.B. weitere Metriken, Visualisierungen)
- [x] CLI-Parameter f√ºr Normalisierung und Thresholds
- [ ] Automatisierte Tests f√ºr alle Workflows
- [ ] Dokumentation weiter ausbauen (z.B. Beispiele, Troubleshooting)


### Erledigte Aufgaben (nicht in urspr√ºnglicher ToDo-Liste)
- [x] Evaluation direkt in DuckDB mit prediction_reference-Tabelle und Schwellenwert-Logik
- [x] Ergebnisse f√ºr verschiedene Thresholds als Schleife in app.py
- [x] Timestamp f√ºr jeden Evaluationslauf in die Datenbank und Reports integriert
- [x] Markdown-Report automatisch um alle Schwellenwert-Auswertungen erweitert
- [x] Doppelte Funktionsdefinitionen entfernt und Code konsolidiert


## üìÖ Letzte Arbeiten (Changelog)

- 2025-07-23: 
    - README modularisiert, CLI-Workflows aktualisiert, neue Abschnitte hinzugef√ºgt
    - Blocking Rules, Schwellenwert-Logik und Evaluation vollst√§ndig implementiert und dokumentiert
    - prediction_reference und prediction_evaluation Tabellen mit Timestamp und Threshold
    - Automatische Schwellenwert-Schleife in app.py
    - Doppelte Funktionsdefinitionen entfernt
    - Markdown-Report um Schwellenwert-Auswertungen erweitert
- 2025-07-22: Modularisierung der CLI, Trennung von Training und Prediction
- 2025-07-21: Markdown-Reporting verbessert, Evaluation in Datenbank ausgelagert

## üìö Regeln & Coding-Standards

- **Imports**: Immer am Anfang eines Moduls
- **Docstrings**: Jede Funktion und jedes Modul erh√§lt einen kurzen Docstring
- **Naming**: Klar, deutsch oder englisch ‚Äì aber konsistent im Modul
- **Modularit√§t**: Keine Logik doppelt, alles in dedizierten Modulen
- **Fehlerbehandlung**: Exceptions immer mit aussagekr√§ftiger Fehlermeldung
- **CLI**: Nur explizite, dokumentierte Parameter zulassen

---
