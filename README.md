# Splink Duplikaterkennung - Production-Ready POC

Ein **modularer Proof of Concept** fÃ¼r Record Linkage und Duplikaterkennung mit deutschen Datenstrukturen. Das System kombiniert Splink v4, persistente DuckDB-Speicherung, umfassende Datennormalisierung und **Referenz-System-Benchmarking** zu einer produktionsreifen LÃ¶sung.

## ğŸš€ Quick Start

```bash
# Installation
uv sync

# VollstÃ¤ndiger Workflow
uv run python -m dublette.app --load-data data.csv --load-reference ref.csv --predict --evaluate

# Schrittweise AusfÃ¼hrung
uv run python -m dublette.app --load-data data.csv
uv run python -m dublette.app --load-reference ref.csv  
uv run python -m dublette.app --predict
uv run python -m dublette.app --evaluate

# Nur Datenverarbeitung (ohne Vorhersage)
uv run python -m dublette.app --load-data data.csv --load-reference ref.csv
```

## âœ¨ Hauptfeatures

### ğŸ—ï¸ **Persistente DuckDB-Architektur**
- **Dauerhafte Speicherung**: Alle Daten in `output/splink_data.duckdb`
- **Intelligente Caching**: Zeitstempel-basierte Aktualisierung
- **Performance**: 70-90% schneller bei WiederholungslÃ¤ufen
- **Backup-freundlich**: Einfacher Export als CSV

### ğŸ‡©ï¿½ **Deutsche Datennormalisierung**
- **Standard-Mode**: Umlaute, StraÃŸenabkÃ¼rzungen, phonetische Regeln
- **Enhanced-Mode**: Soundex, Fuzzy-Matching, NLP-Adressen (mit jellyfish)
- **Backward-Compatible**: Funktioniert mit bestehenden Daten
- **Flexibel**: Ein-/ausschaltbar per CLI-Parameter

### ğŸ“Š **Umfassende Evaluation**
- **6-Plot-Analysis**: Wahrscheinlichkeitsverteilung, Threshold-SensitivitÃ¤t, QualitÃ¤tsindikatoren
- **Markdown-Bericht**: Automatisch generierter Evaluationsbericht
- **VerstÃ¤ndliche Metriken**: Deutsche ErklÃ¤rungen und Empfehlungen
- **Visualisierungen**: 4 verschiedene Plot-Sets fÃ¼r tiefe Einblicke

### âš¡ **Vereinfachte Splink-Features**
- **Single-Table-Deduplikation**: Fokus auf Duplikaterkennung innerhalb einer Datenquelle
- **Kombinierte Blocking Rules**: NAME+VORNAME, PLZ+ORT, phonetische Ã„hnlichkeit
- **Deutsche Datenstrukturen**: Optimiert fÃ¼r SATZNR, NAME, VORNAME, etc.
- **Threshold-basierte Klassifikation**: Standard-Threshold 0.8

## ğŸ”§ Vereinfachtes CLI Interface

Das CLI wurde auf **4 essenzielle Parameter** reduziert fÃ¼r maximale Klarheit:

### **Kern-Usage**

```bash
# VollstÃ¤ndiger Workflow
uv run python -m dublette.app --load-data companies.csv --load-reference duplicates.csv --predict --evaluate

# Schrittweise AusfÃ¼hrung
uv run python -m dublette.app --load-data companies.csv
uv run python -m dublette.app --load-reference duplicates.csv
uv run python -m dublette.app --predict
uv run python -m dublette.app --evaluate

# Nur Datenverarbeitung
uv run python -m dublette.app --load-data companies.csv --load-reference duplicates.csv

# Ohne Referenz-System
uv run python -m dublette.app --load-data companies.csv --predict --evaluate
```

### **Parameter**

| Parameter | Beschreibung |
|-----------|-------------|
| `--load-data FILE` | CSV-Datei einlesen â†’ `company_data_raw` â†’ `company_data` (normalisiert) |
| `--load-reference FILE` | CSV mit Referenz-Duplikaten â†’ `reference_duplicates` (SATZNR_1, SATZNR_2) |
| `--predict` | Single-Table-Deduplikation â†’ `predictions` + `target_table` + `predictions_with_reference` |
| `--evaluate` | Evaluation-Report und Statistiken generieren |

### **Automatische Features**

- **Datennormalisierung**: Enhanced-Mode standardmÃ¤ÃŸig aktiviert
- **Datenbank-Persistenz**: Alle Daten in `output/splink_data.duckdb` gespeichert
- **CSV-Export**: Ergebnisse automatisch in `output/`-Verzeichnis gespeichert
- **Referenz-Integration**: Automatischer Vergleich mit Referenz-System wenn verfÃ¼gbar
- **Threshold-Optimierung**: Standard-Threshold 0.8 mit SensitivitÃ¤ts-Analyse

### **HÃ¤ufige Workflows**

```bash
# Produktions-Deduplikation mit Benchmarking
uv run python -m dublette.app --load-data customer_data.csv --load-reference known_duplicates.csv --predict --evaluate

# Evaluation bestehender Predictions
uv run python -m dublette.app --evaluate

# Batch-Verarbeitung
for file in *.csv; do
  uv run python -m dublette.app --load-data "$file" --predict --evaluate
done

# Daten vorbereiten fÃ¼r spÃ¤tere Verarbeitung
uv run python -m dublette.app --load-data large_dataset.csv --load-reference ref.csv
# ... spÃ¤ter ...
uv run python -m dublette.app --predict --evaluate
```

## ğŸ—‚ï¸ Ausgabefiles

```
output/
â”œâ”€â”€ splink_data.duckdb              # Persistente Hauptdatenbank (DuckDB)
â”œâ”€â”€ evaluation_report.md            # Umfassender Evaluationsbericht mit Referenz-Vergleich
â”œâ”€â”€ comprehensive_evaluation_analysis.png
â”œâ”€â”€ detailed_threshold_analysis.png
â”œâ”€â”€ match_quality_heatmap.png
â”œâ”€â”€ match_probability_distribution.png
â”œâ”€â”€ predictions.csv                 # Splink-Vorhersagen
â”œâ”€â”€ target_table.csv               # Deduplizierte Zieltabelle
â””â”€â”€ predictions_with_reference.csv  # Erweiterte Vorhersagen mit Referenz-Flags
```

## ğŸ›ï¸ Architektur

### **Module**
- `app.py`: Vereinfachtes 4-Parameter-CLI mit Single-Table-Fokus
- `data/normalization.py`: Enhanced-Normalisierung mit SATZNR-Erhaltung  
- `database/connection.py`: DuckDB-Setup mit persistenter Speicherung und Referenz-Handling
- `detection/splink_config.py`: Single-Table-Blocking-Rules fÃ¼r deutsche Datenstrukturen
- `evaluation/metrics.py`: Evaluation mit Referenz-System-Vergleich und Visualisierungen

### **Datenmodell (Deutsche Spaltennamen)**
```
SATZNR          # Eindeutige ID
NAME            # Nachname/Firmenname  
VORNAME         # Vorname
GEBURTSDATUM    # Datum (YYYY-MM-DD)
GESCHLECHT      # M/W/D
LAND            # LÃ¤ndercode (DE/AT/CH)
POSTLEITZAHL    # Deutsche PLZ
ORT             # Stadt
ADRESSZEILE     # VollstÃ¤ndige Adresse
```

### **Datenbank-Tabellen**
```
company_data_raw         # Original CSV-Daten
company_data             # Normalisierte CSV-Daten (Single-Table)
predictions              # Splink-Ergebnisse
target_table             # Deduplizierte DatensÃ¤tze
reference_duplicates     # Referenz-System-Duplikate (SATZNR_1, SATZNR_2)
predictions_with_reference # Enhanced Predictions mit Referenz-Flags
```

## ğŸš€ Performance

### **Benchmark-Ergebnisse**
- **Erstes Laden**: Setup-Zeit fÃ¼r Datenbank und Normalisierung
- **Wiederholte LÃ¤ufe**: 70-90% schneller durch DuckDB-Caching
- **Enhanced Normalization**: StandardmÃ¤ÃŸig aktiviert, deutlich bessere QualitÃ¤t
- **Single-Table-Fokus**: Optimiert fÃ¼r Deduplikation (keine Multi-Table-Overhead)

### **Speichereffizienz**
- **DuckDB vs CSV**: 50-70% weniger Speicherplatz
- **Persistente Speicherung**: Keine Neuberechnung bei Wiederholung
- **Cleanup**: Automatische Bereinigung temporÃ¤rer Daten

### **Workflow-Optimierung**
- **4-Parameter-CLI**: Maximale Klarheit und Einfachheit
- **Schrittweise AusfÃ¼hrung**: Einzelne Phasen separat ausfÃ¼hrbar
- **Referenz-Integration**: Nahtloses Benchmarking gegen bestehende Systeme

---

**Production-ready Single-Table-Deduplikation mit deutscher Lokalisierung und persistenter DuckDB-Architektur! ğŸ‡©ğŸ‡ªâš¡**