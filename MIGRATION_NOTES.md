# Migration Notes - Vereinfachung auf 4 Kernfunktionen

**Datum:** 14. Juli 2025  
**Ã„nderung:** Refaktorierung von komplexem Multi-Mode CLI auf 4 essenzielle Parameter

## ğŸ”„ Was hat sich geÃ¤ndert?

### âŒ **Entfernte Features**
- **Testdatengenerierung** (`--generate-test-data`)
- **Multi-Table-Linking** (company_data_a/b)
- **Komplexe Prediction-Modi** (`--predict input|generated`)
- **Separater Referenz-Stats-Modus** (`--reference-stats`)

### âœ… **Neue CLI-Struktur**
```bash
# ALT (komplex)
uv run python -m dublette.app --generate-test-data --predict generated
uv run python -m dublette.app --input-file data.csv --reference-file ref.csv --predict input

# NEU (vereinfacht)
uv run python -m dublette.app --load-data data.csv --load-reference ref.csv --predict --evaluate
```

### ğŸ¯ **Die 4 Kernfunktionen**
1. **`--load-data FILE`**: CSV â†’ company_data_raw â†’ company_data (normalisiert)
2. **`--load-reference FILE`**: CSV â†’ reference_duplicates (SATZNR_1, SATZNR_2)
3. **`--predict`**: Single-Table-Deduplikation â†’ predictions + target_table + predictions_with_reference
4. **`--evaluate`**: Report + Referenz-Vergleich + Statistiken

## ğŸ”§ **Migration fÃ¼r bestehende Nutzer**

### Alte Kommandos â†’ Neue Kommandos
```bash
# Testdaten (ALT - nicht mehr verfÃ¼gbar)
--generate-test-data --predict generated
# â†’ Nutzen Sie echte CSV-Dateien

# CSV-Verarbeitung (ALT)
--input-file data.csv --predict input
# â†’ NEU
--load-data data.csv --predict

# Mit Referenz (ALT)
--input-file data.csv --reference-file ref.csv --predict input
# â†’ NEU  
--load-data data.csv --load-reference ref.csv --predict

# Referenz-Statistiken (ALT)
--reference-stats
# â†’ NEU (integriert in)
--evaluate
```

## ğŸ“Š **Vorteile der Vereinfachung**

### ğŸ¯ **Klarheit**
- Nur noch 4 Parameter statt 7
- Eindeutige Funktionszuordnung
- Keine Moduserkennung mehr nÃ¶tig

### âš¡ **Performance**
- Fokus auf Single-Table (hÃ¤ufigster Use Case)
- Weniger Code-Pfade = weniger Fehlerquellen
- Optimierte DuckDB-Nutzung

### ğŸ› ï¸ **Wartbarkeit**
- Kleinere, fokussierte Funktionen
- Weniger AbhÃ¤ngigkeiten
- Einfachere Tests

## ğŸ—ƒï¸ **Datenbank-Schema (unverÃ¤ndert)**
```
company_data_raw         # Original CSV-Daten
company_data             # Normalisierte CSV-Daten
predictions              # Splink-Ergebnisse  
target_table             # Deduplizierte DatensÃ¤tze
reference_duplicates     # Referenz-System-Duplikate
predictions_with_reference # Enhanced Predictions mit Referenz-Flags
```

## ğŸš€ **Empfohlener Workflow**

### 1. **Datenload**
```bash
uv run python -m dublette.app --load-data companies.csv --load-reference duplicates.csv
```

### 2. **Vorhersage**
```bash
uv run python -m dublette.app --predict
```

### 3. **Evaluation**
```bash
uv run python -m dublette.app --evaluate
```

### 4. **Alles zusammen**
```bash
uv run python -m dublette.app --load-data companies.csv --load-reference duplicates.csv --predict --evaluate
```

## ğŸ“‹ **Checkliste fÃ¼r Migration**

- [ ] Vorhandene Scripts auf neue Parameter umstellen
- [ ] Testdaten durch echte CSV-Dateien ersetzen
- [ ] `--reference-stats` durch `--evaluate` ersetzen  
- [ ] Multi-Table-Workflows auf Single-Table umstellen
- [ ] Dokumentation und Tutorials aktualisieren

## ğŸ”® **Zukunft**

Diese Vereinfachung bildet die Basis fÃ¼r:
- Bessere API-Integration
- Web-Interface-Entwicklung
- Production-Deployment
- Erweiterte Batch-Verarbeitung

---
*Diese Migration fokussiert das System auf die 90% Use Cases und macht es deutlich einfacher zu nutzen und zu warten.* ğŸ¯
